{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF7uhpM720L7"
      },
      "source": [
        "# Projet ML Team Zoom "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIiHQmMF1MGJ"
      },
      "source": [
        "\n",
        "For example, you should keep track of the reported accuracies of the different submissions and also what changes you introduced to have some improvement in your score.\n",
        "Try to separate the preprocessing into a separate python file that you import from the main python file. So in your notebook, we expect to see at least:\n",
        "What is the base-rate of the problem?\n",
        "* A table with all of the classification techniques that we saw in the class (logistic regression, kNN, Decision trees,...) and indicate the parameters you used.\n",
        "* Your progression of accuracies in a graph, and which technique (with what parameters) achieved it.\n",
        "* Go deeper. How can you improve the model? Do both of the following.\n",
        "* Feature engineering. \n",
        "* Hyper-parameter optimization.\n",
        " \n",
        "\n",
        "Note: You should ONLY use techniques that we used in the class. No other techniques are allowed. We should first master those techniques!\n",
        "\n",
        "\n",
        "```\n",
        "# Free Petit Beurre \n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECXe-WUW01be"
      },
      "source": [
        "Things to do: \n",
        "\n",
        "\n",
        "*   Fix Location\n",
        "*   Pre process the data ( look for adding stuff)\n",
        "*  Try Hard our model \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDrZYuWk27oN"
      },
      "source": [
        "## Import and Load Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "a = 10\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBnwpYE72_27"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import spacy"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3e4ce66fa882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLk1JEsw3FAm",
        "outputId": "f9d04792-0e84-4901-9f0d-b22ec9629c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#Load Data:\n",
        "train = pd.read_csv(\"https://aicrowd-production.s3.eu-central-1.amazonaws.com/dataset_files/challenge_601/82653de5-2ed1-4782-959e-23eba75d67a9_training_data.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJ6IZH6GWKDCCDFAQ%2F20201115%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Date=20201115T214351Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=66d1423cd59626ebe2d729aca0863b10315b470f864ba50d4b79cb91bd48857f\")\n",
        "test=pd.read_csv(\"https://aicrowd-production.s3.eu-central-1.amazonaws.com/dataset_files/challenge_601/5fc21f33-b209-4b07-ad70-a69020dfd2cf_test_data.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJ6IZH6GWKDCCDFAQ%2F20201115%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Date=20201115T214351Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=874ea81177c063d186c18a82c9443f13e3e2a3bef3b720fb1adbf3d4af561b3b\")\n",
        "train.head(100)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-84c0e49bbeb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load Data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://aicrowd-production.s3.eu-central-1.amazonaws.com/dataset_files/challenge_601/82653de5-2ed1-4782-959e-23eba75d67a9_training_data.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJ6IZH6GWKDCCDFAQ%2F20201115%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Date=20201115T214351Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=66d1423cd59626ebe2d729aca0863b10315b470f864ba50d4b79cb91bd48857f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://aicrowd-production.s3.eu-central-1.amazonaws.com/dataset_files/challenge_601/5fc21f33-b209-4b07-ad70-a69020dfd2cf_test_data.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJ6IZH6GWKDCCDFAQ%2F20201115%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Date=20201115T214351Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=874ea81177c063d186c18a82c9443f13e3e2a3bef3b720fb1adbf3d4af561b3b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2PoHEs_4P9r"
      },
      "source": [
        "## Explorate the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYVSlz4x4S6T",
        "outputId": "7a24807e-c1f0-4064-99cb-82815087edd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoHBm8-8xpqg",
        "outputId": "c8a8519e-559d-4f77-e753-e6eb8d5c6982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train[\"target\"].value_counts()\n",
        "base_rate= 3701/(3701+2770)\n",
        "print(\"Le base rate est de\"+ \" \"+str(base_rate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfX58xs7wV4I",
        "outputId": "68e9b614-4731-4ea2-e0d7-434226254045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbAO2Psa4V4V",
        "outputId": "61b91679-6e2d-44a0-e129-80cc9d4ad7b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPnt04hF4jvT",
        "outputId": "13c8d7af-9a5c-4d90-ba5c-e1f8cebd0dbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DRkN0Z95OAj"
      },
      "source": [
        "## Cleaning the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTp-RudU5RJT",
        "outputId": "cc74b1e7-dd74-42fc-fa93-23de76496437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train[\"keyword\"].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYuIEDO55pEf",
        "outputId": "eb7b0c41-098b-4ea6-a537-f3c546c6fa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train[train[\"keyword\"].isnull()==True]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIfSTjUF5QD8",
        "outputId": "97c21113-17b3-455d-f1c2-6f3dcedbb0a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Replace %20 by space:\n",
        "\n",
        "train[\"keyword\"]= train[\"keyword\"].astype(str)\n",
        "for i in range(len(train[\"keyword\"])):\n",
        "  train[\"keyword\"].iloc[i]=train[\"keyword\"].iloc[i].replace(\"%20\",\" \")\n",
        "  print(train[\"keyword\"].iloc[i])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70u3984srQd7",
        "outputId": "f65b8caf-6e59-4575-f0cb-e3c3faf1dbb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install pycountry "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O5fBsZFqavO",
        "outputId": "0e67d651-caf0-49c8-f618-bd9951913525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#Probleme USA en Mode Etat: \n",
        "import pycountry\n",
        "train[\"location\"]= train[\"location\"].astype(str)\n",
        "\n",
        "def do_fuzzy_search(country):\n",
        "    try:\n",
        "        result = pycountry.countries.search_fuzzy(country)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "    else:\n",
        "        return result[0].alpha_3\n",
        "\n",
        "\n",
        "train[\"country_code\"] = train[\"location\"].apply(lambda country: do_fuzzy_search(country))\n",
        "\n",
        "train\n",
        "\n",
        "#Hotfix: \n",
        "#Nan \n",
        "#States\n",
        "#States"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEgI3KDbvl5M"
      },
      "source": [
        "## Pre-Processing Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnoBcAZovxt3"
      },
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD47CWWnxhih",
        "outputId": "b1cdd1c6-dee8-4acd-a5cd-e6d0a393ddf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "# Load English language model\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "message= str(train[\"text\"])\n",
        "my_word= sp(message)\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "punctuations = string.punctuation\n",
        "# Create tokenizer function\n",
        "\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = sp(sentence)\n",
        "\n",
        "    # Lemmatize each token and convert each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() and word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens\n",
        "\n",
        "\n",
        "for i in range(len(train[\"text\"])):\n",
        "  train[\"text\"].iloc[i]=\" \".join(spacy_tokenizer(train[\"text\"].iloc[i]))\n",
        "\n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9rPXpFCvqew"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlJMm-iRvysI",
        "outputId": "8f1b1d20-0981-440c-85c2-f47fc3212e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "X = train[[\"text\",\"keyword\",\"country_code\"]] # the features we want to analyze\n",
        "ylabels = train['target'] # the labels, or answers, we want to test against\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=72)\n",
        "\n",
        "X_train\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuowEyKVvsWB"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ1B46sBvsbW",
        "outputId": "d37621cf-b0c6-4a75-c3dc-94a30179972b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "#Add command for the submission"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}